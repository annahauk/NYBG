{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ! kaggle competitions download -c bttai-nybg-2024"
      ],
      "metadata": {
        "id": "CSea07t3_-ap"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! unzip \"bttai-nybg-2024\" -d \"bttai-nybg-2024\""
      ],
      "metadata": {
        "id": "8pJ18j8xBfRC"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "8e7hdNtcHF84"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import InceptionV3, DenseNet121\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename_train = \"./bttai-nybg-2024/BTTAIxNYBG-train.csv\"\n",
        "df_train = pd.read_csv(filename_train)\n",
        "filename_test = \"./bttai-nybg-2024/BTTAIxNYBG-test.csv\"\n",
        "df_test = pd.read_csv(filename_test)\n",
        "filename_val = \"./bttai-nybg-2024/BTTAIxNYBG-validation.csv\"\n",
        "df_val = pd.read_csv(filename_val)"
      ],
      "metadata": {
        "id": "1-3KRIwiqCXO"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_directory = \"./bttai-nybg-2024/BTTAIxNYBG-train/BTTAIxNYBG-train\"\n",
        "validation_image_directory = \"./bttai-nybg-2024/BTTAIxNYBG-validation/BTTAIxNYBG-validation\"\n"
      ],
      "metadata": {
        "id": "s8MSJG56sNQA"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input)"
      ],
      "metadata": {
        "id": "4Hi5WGALqE0U"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=df_train,\n",
        "    directory=train_image_directory,\n",
        "    x_col='imageFile',\n",
        "    y_col='classLabel',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x98zqegqIf-",
        "outputId": "0ab1d95d-6e8b-4538-8df4-16c3ae9fc894"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 81946 validated image filenames belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=df_val,\n",
        "    directory=validation_image_directory,\n",
        "    x_col='imageFile',\n",
        "    y_col='classLabel',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQZdGU34qK_q",
        "outputId": "5f991645-8dcf-485c-b49c-0f5aba17471a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10244 validated image filenames belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inception_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "densenet_base = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"
      ],
      "metadata": {
        "id": "as9scFb6qNU4"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in inception_base.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in densenet_base.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "ofQpqT2_qP3a"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception_output = GlobalAveragePooling2D()(inception_base.output)\n",
        "densenet_output = GlobalAveragePooling2D()(densenet_base.output)"
      ],
      "metadata": {
        "id": "cPe0XqorqScN"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concatenated = Concatenate()([inception_output, densenet_output])"
      ],
      "metadata": {
        "id": "BGRyDxmwqUtP"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = list(df_train[\"classLabel\"].unique())"
      ],
      "metadata": {
        "id": "cOUexxjKqoEj"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Dense(1024, activation='relu')(concatenated)\n",
        "predictions = Dense(len(classes), activation='softmax')(x)"
      ],
      "metadata": {
        "id": "2c0C0aH7qYbe"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[inception_base.input, densenet_base.input], outputs=predictions)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "o8d2AYx-qpPy"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we now have two inputs, we need to adjust our data generators accordingly\n",
        "def dual_generator(generator):\n",
        "    while True:\n",
        "        x, y = next(generator)\n",
        "        yield [x, x], y"
      ],
      "metadata": {
        "id": "5bKeYUNAq3mx"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dual_generator = dual_generator(train_generator)\n",
        "validation_dual_generator = dual_generator(validation_generator)"
      ],
      "metadata": {
        "id": "jgZjZukxq6fo"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=3,  # number of epochs with no improvement after which training will be stopped\n",
        "    verbose=1,\n",
        "    mode='min',  # the training will stop when the quantity monitored has stopped decreasing\n",
        "    restore_best_weights=True  # restore model weights from the epoch with the best value of the monitored quantity\n",
        ")"
      ],
      "metadata": {
        "id": "u6Su4GxPDqGf"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath='best_Emodel',  # path where to save the model\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,  # only save a model if `val_loss` has improved\n",
        "    verbose=1,\n",
        "    mode='min'\n",
        ")"
      ],
      "metadata": {
        "id": "_QX88F-VEAS8"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_dual_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=10,\n",
        "    validation_data=validation_dual_generator,\n",
        "    validation_steps=len(validation_generator),\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "fH6sDJFwD1Pe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960b55c9-482a-4e6e-faf7-ccfb25e8c644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2561/2561 [==============================] - ETA: 0s - loss: 0.9354 - accuracy: 0.6761\n",
            "Epoch 1: val_loss improved from inf to 0.66147, saving model to best_Emodel\n",
            "2561/2561 [==============================] - 726s 279ms/step - loss: 0.9354 - accuracy: 0.6761 - val_loss: 0.6615 - val_accuracy: 0.7723\n",
            "Epoch 2/10\n",
            "2561/2561 [==============================] - ETA: 0s - loss: 0.6512 - accuracy: 0.7752\n",
            "Epoch 2: val_loss improved from 0.66147 to 0.58250, saving model to best_Emodel\n",
            "2561/2561 [==============================] - 708s 277ms/step - loss: 0.6512 - accuracy: 0.7752 - val_loss: 0.5825 - val_accuracy: 0.7978\n",
            "Epoch 3/10\n",
            "2561/2561 [==============================] - ETA: 0s - loss: 0.5740 - accuracy: 0.7997\n",
            "Epoch 3: val_loss improved from 0.58250 to 0.53149, saving model to best_Emodel\n",
            "2561/2561 [==============================] - 712s 278ms/step - loss: 0.5740 - accuracy: 0.7997 - val_loss: 0.5315 - val_accuracy: 0.8178\n",
            "Epoch 4/10\n",
            "2561/2561 [==============================] - ETA: 0s - loss: 0.5234 - accuracy: 0.8174\n",
            "Epoch 4: val_loss did not improve from 0.53149\n",
            "2561/2561 [==============================] - 661s 258ms/step - loss: 0.5234 - accuracy: 0.8174 - val_loss: 0.5358 - val_accuracy: 0.8103\n",
            "Epoch 5/10\n",
            "2561/2561 [==============================] - ETA: 0s - loss: 0.4912 - accuracy: 0.8285\n",
            "Epoch 5: val_loss did not improve from 0.53149\n",
            "2561/2561 [==============================] - 660s 258ms/step - loss: 0.4912 - accuracy: 0.8285 - val_loss: 0.5777 - val_accuracy: 0.8037\n",
            "Epoch 6/10\n",
            "2561/2561 [==============================] - ETA: 0s - loss: 0.4645 - accuracy: 0.8385\n",
            "Epoch 6: val_loss improved from 0.53149 to 0.47535, saving model to best_Emodel\n",
            "2561/2561 [==============================] - 723s 283ms/step - loss: 0.4645 - accuracy: 0.8385 - val_loss: 0.4754 - val_accuracy: 0.8319\n",
            "Epoch 7/10\n",
            "2561/2561 [==============================] - ETA: 0s - loss: 0.4445 - accuracy: 0.8443\n",
            "Epoch 7: val_loss improved from 0.47535 to 0.45687, saving model to best_Emodel\n",
            "2561/2561 [==============================] - 724s 283ms/step - loss: 0.4445 - accuracy: 0.8443 - val_loss: 0.4569 - val_accuracy: 0.8401\n",
            "Epoch 8/10\n",
            "2561/2561 [==============================] - ETA: 0s - loss: 0.4276 - accuracy: 0.8507\n",
            "Epoch 8: val_loss did not improve from 0.45687\n",
            "2561/2561 [==============================] - 665s 260ms/step - loss: 0.4276 - accuracy: 0.8507 - val_loss: 0.4693 - val_accuracy: 0.8381\n",
            "Epoch 9/10\n",
            "1474/2561 [================>.............] - ETA: 4:08 - loss: 0.4091 - accuracy: 0.8557"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dual_generator_forTest(generator):\n",
        "    while True:\n",
        "        x, _ = next(generator)\n",
        "        yield [x, x]"
      ],
      "metadata": {
        "id": "e__8AsdIIfry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input)"
      ],
      "metadata": {
        "id": "8SeUgsGBI5OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=df_test,\n",
        "    directory=\"./bttai-nybg-2024/BTTAIxNYBG-test/BTTAIxNYBG-test\",\n",
        "    x_col=\"imageFile\",\n",
        "    y_col= None,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode= None,\n",
        "    shuffle=False)  # No need to shuffle test data"
      ],
      "metadata": {
        "id": "AZnIwlEyIwAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dual_generator = dual_generator_forTest(test_generator)"
      ],
      "metadata": {
        "id": "rDMJCtQVI_Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_dual_generator, steps=len(test_generator))\n",
        "predicted_classes = np.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "id": "b6SIH4E_JBvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame({\n",
        "    'uniqueID': df_test['uniqueID'],\n",
        "    'classID': predicted_classes\n",
        "})"
      ],
      "metadata": {
        "id": "qO1-cAItWzZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df.head()"
      ],
      "metadata": {
        "id": "IFxGsXqPW2Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "wfnVdt4sW36m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions submit -c bttai-nybg-2024 -f submission.csv -m \"Starflowers-NYC (Using Emodel)\""
      ],
      "metadata": {
        "id": "lr5KqwwmW6d2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}