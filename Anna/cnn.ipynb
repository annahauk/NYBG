{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_directory = \"/Users/annahauk/Desktop/NYBG/bttai-nybg-2024/BTTAIxNYBG-train/BTTAIxNYBG-train\"\n",
    "validation_image_directory = \"/Users/annahauk/Desktop/NYBG/bttai-nybg-2024/BTTAIxNYBG-validation/BTTAIxNYBG-validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train = \"/Users/annahauk/Desktop/NYBG/bttai-nybg-2024/BTTAIxNYBG-train.csv\"\n",
    "df_train = pd.read_csv(filename_train, header = 0)\n",
    "filename_test = \"/Users/annahauk/Desktop/NYBG/bttai-nybg-2024/BTTAIxNYBG-test.csv\"\n",
    "df_test = pd.read_csv(filename_test, header = 0)\n",
    "filename_val = \"/Users/annahauk/Desktop/NYBG/bttai-nybg-2024/BTTAIxNYBG-validation.csv\"\n",
    "df_val = pd.read_csv(filename_val, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>classLabel</th>\n",
       "      <th>classID</th>\n",
       "      <th>source</th>\n",
       "      <th>imageFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>occluded-specimens</td>\n",
       "      <td>8</td>\n",
       "      <td>L</td>\n",
       "      <td>a1a8b48e8cb142b3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>microscope-slides</td>\n",
       "      <td>6</td>\n",
       "      <td>L</td>\n",
       "      <td>79599db2ac9092b6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>illustrations-color</td>\n",
       "      <td>2</td>\n",
       "      <td>BHL</td>\n",
       "      <td>c449696f2f0d0d92.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>illustrations-color</td>\n",
       "      <td>2</td>\n",
       "      <td>P</td>\n",
       "      <td>80a8f4a393b4e08c.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>animal-specimens</td>\n",
       "      <td>0</td>\n",
       "      <td>AK</td>\n",
       "      <td>041a1c6e73313638.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>occluded-specimens</td>\n",
       "      <td>8</td>\n",
       "      <td>L</td>\n",
       "      <td>ccf1b1ccacb8f8b3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>live-plants</td>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>246c8e9612111a24.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>biocultural-specimens</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>b0b337313164a0f0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>microscope-slides</td>\n",
       "      <td>6</td>\n",
       "      <td>L</td>\n",
       "      <td>b3931bc4cc2b2925.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>illustrations-gray</td>\n",
       "      <td>3</td>\n",
       "      <td>BR</td>\n",
       "      <td>ebf7674e4c2c0e6e.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID             classLabel  classID source             imageFile\n",
       "0         2     occluded-specimens        8      L  a1a8b48e8cb142b3.jpg\n",
       "1         3      microscope-slides        6      L  79599db2ac9092b6.jpg\n",
       "2         4    illustrations-color        2    BHL  c449696f2f0d0d92.jpg\n",
       "3         5    illustrations-color        2      P  80a8f4a393b4e08c.jpg\n",
       "4         6       animal-specimens        0     AK  041a1c6e73313638.jpg\n",
       "5         8     occluded-specimens        8      L  ccf1b1ccacb8f8b3.jpg\n",
       "6        11            live-plants        4     US  246c8e9612111a24.jpg\n",
       "7        12  biocultural-specimens        1      C  b0b337313164a0f0.jpg\n",
       "8        13      microscope-slides        6      L  b3931bc4cc2b2925.jpg\n",
       "9        15     illustrations-gray        3     BR  ebf7674e4c2c0e6e.jpg"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['uniqueID', 'classLabel', 'classID', 'source', 'imageFile'], dtype='object')\n",
      "Index(['uniqueID', 'classLabel', 'classID', 'source', 'imageFile'], dtype='object')\n",
      "Index(['uniqueID', 'imageFile'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns)\n",
    "print(df_val.columns)\n",
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a Small VGGNet using df_train, df_test, and df_val\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "df_train[\"classID\"] = df_train[\"classID\"].astype(str)\n",
    "df_val[\"classID\"] = df_val[\"classID\"].astype(str)\n",
    "\n",
    "# load the VGG16 network, ensuring the head FC layer sets are left off\n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
    "    input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the head of the model that will be placed on top of the base model\n",
    "headModel = baseModel.output\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dense(64, activation=\"relu\")(headModel)\n",
    "headModel = Dense(32, activation=\"relu\")(headModel)\n",
    "headModel = Dense(16, activation=\"relu\")(headModel)\n",
    "headModel = Dense(8, activation=\"relu\")(headModel)\n",
    "headModel = Dense(4, activation=\"relu\")(headModel)\n",
    "headModel = Dense(2, activation=\"relu\")(headModel)\n",
    "headModel = Dense(10, activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# compile our model (this needs to be done after our setting our\n",
    "# layers to being non-trainable)\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=0.001)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network for a few epochs (all other layers\n",
    "# are frozen) -- this will allow the new FC layers to start to become\n",
    "# initialized with actual \"learned\" values versus pure random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "Found 81945 validated image filenames belonging to 10 classes.\n",
      "Found 10244 validated image filenames belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"imageFile\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train the model using the training data\n",
    "print(\"[INFO] training head...\")\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=df_train, directory=train_image_directory, x_col=\"imageFile\", y_col=\"classID\", class_mode=\"sparse\", target_size=(224, 224), batch_size=32)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_dataframe(dataframe=df_val, directory=validation_image_directory, x_col=\"imageFile\", y_col=\"classID\", class_mode=\"sparse\", target_size=(224, 224), batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THIS ONE TAKES A WHILE TO RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   7/2561 [..............................] - ETA: 1:26:28 - loss: 2.3002 - accuracy: 0.0938"
     ]
    }
   ],
   "source": [
    "model.fit(train_generator, validation_data=val_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "# create a generator for the test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=df_test, directory=train_image_directory, x_col=\"imageFile\", y_col=None, class_mode=None, target_size=(224, 224), batch_size=32, shuffle=False)\n",
    "\n",
    "# use the model to make predictions\n",
    "predictions = model.predict(test_generator)\n",
    "\n",
    "# the predictions are probabilities for each class, so take the class with the highest probability as the prediction\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"[INFO] evaluating network...\")\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"test loss: {:.2f}\".format(test_loss))\n",
    "print(\"test accuracy: {:.2f}\".format(test_acc))\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(\"bttai-nybg-2024.model\", save_format=\"smallVGNNET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "N = 10\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), model.history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), model.history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), model.history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), model.history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
