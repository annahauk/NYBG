{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_directory = \"/Users/annahauk/Desktop/NYBG/bttai-nybg-2024/BTTAIxNYBG-train/BTTAIxNYBG-train\"\n",
    "validation_image_directory = \"/Users/annahauk/Desktop/NYBG/bttai-nybg-2024/BTTAIxNYBG-validation/BTTAIxNYBG-validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train = \"/Users/annahauk/Desktop/NYBG/bttai-nybg-2024/BTTAIxNYBG-train.csv\"\n",
    "df_train = pd.read_csv(filename_train, header = 0)\n",
    "filename_test = \"/Users/annahauk/Desktop/NYBG/bttai-nybg-2024/BTTAIxNYBG-test.csv\"\n",
    "df_test = pd.read_csv(filename_test, header = 0)\n",
    "filename_val = \"/Users/annahauk/Desktop/NYBG/bttai-nybg-2024/BTTAIxNYBG-validation.csv\"\n",
    "df_val = pd.read_csv(filename_val, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>classLabel</th>\n",
       "      <th>classID</th>\n",
       "      <th>source</th>\n",
       "      <th>imageFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>occluded-specimens</td>\n",
       "      <td>8</td>\n",
       "      <td>L</td>\n",
       "      <td>a1a8b48e8cb142b3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>microscope-slides</td>\n",
       "      <td>6</td>\n",
       "      <td>L</td>\n",
       "      <td>79599db2ac9092b6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>illustrations-color</td>\n",
       "      <td>2</td>\n",
       "      <td>BHL</td>\n",
       "      <td>c449696f2f0d0d92.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>illustrations-color</td>\n",
       "      <td>2</td>\n",
       "      <td>P</td>\n",
       "      <td>80a8f4a393b4e08c.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>animal-specimens</td>\n",
       "      <td>0</td>\n",
       "      <td>AK</td>\n",
       "      <td>041a1c6e73313638.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>occluded-specimens</td>\n",
       "      <td>8</td>\n",
       "      <td>L</td>\n",
       "      <td>ccf1b1ccacb8f8b3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>live-plants</td>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>246c8e9612111a24.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>biocultural-specimens</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>b0b337313164a0f0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>microscope-slides</td>\n",
       "      <td>6</td>\n",
       "      <td>L</td>\n",
       "      <td>b3931bc4cc2b2925.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>illustrations-gray</td>\n",
       "      <td>3</td>\n",
       "      <td>BR</td>\n",
       "      <td>ebf7674e4c2c0e6e.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID             classLabel  classID source             imageFile\n",
       "0         2     occluded-specimens        8      L  a1a8b48e8cb142b3.jpg\n",
       "1         3      microscope-slides        6      L  79599db2ac9092b6.jpg\n",
       "2         4    illustrations-color        2    BHL  c449696f2f0d0d92.jpg\n",
       "3         5    illustrations-color        2      P  80a8f4a393b4e08c.jpg\n",
       "4         6       animal-specimens        0     AK  041a1c6e73313638.jpg\n",
       "5         8     occluded-specimens        8      L  ccf1b1ccacb8f8b3.jpg\n",
       "6        11            live-plants        4     US  246c8e9612111a24.jpg\n",
       "7        12  biocultural-specimens        1      C  b0b337313164a0f0.jpg\n",
       "8        13      microscope-slides        6      L  b3931bc4cc2b2925.jpg\n",
       "9        15     illustrations-gray        3     BR  ebf7674e4c2c0e6e.jpg"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['uniqueID', 'classLabel', 'classID', 'source', 'imageFile'], dtype='object')\n",
      "Index(['uniqueID', 'classLabel', 'classID', 'source', 'imageFile'], dtype='object')\n",
      "Index(['uniqueID', 'imageFile'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns)\n",
    "print(df_val.columns)\n",
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a Small VGGNet using df_train, df_test, and df_val\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "df_train[\"classID\"] = df_train[\"classID\"].astype(str)\n",
    "df_val[\"classID\"] = df_val[\"classID\"].astype(str)\n",
    "\n",
    "# load the VGG16 network, ensuring the head FC layer sets are left off\n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
    "    input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the head of the model that will be placed on top of the base model\n",
    "headModel = baseModel.output\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dense(64, activation=\"relu\")(headModel)\n",
    "headModel = Dense(32, activation=\"relu\")(headModel)\n",
    "headModel = Dense(16, activation=\"relu\")(headModel)\n",
    "headModel = Dense(8, activation=\"relu\")(headModel)\n",
    "headModel = Dense(4, activation=\"relu\")(headModel)\n",
    "headModel = Dense(2, activation=\"relu\")(headModel)\n",
    "headModel = Dense(10, activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# import the legacy SGD optimizer\n",
    "from tensorflow.keras.optimizers.legacy import SGD\n",
    "\n",
    "# compile our model (this needs to be done after our setting our\n",
    "# layers to being non-trainable)\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=0.001)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "# train the head of the network for a few epochs (all other layers\n",
    "# are frozen) -- this will allow the new FC layers to start to become\n",
    "# initialized with actual \"learned\" values versus pure random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "Found 81945 validated image filenames belonging to 10 classes.\n",
      "Found 10244 validated image filenames belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"imageFile\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train the model using the training data\n",
    "print(\"[INFO] training head...\")\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=df_train, directory=train_image_directory, x_col=\"imageFile\", y_col=\"classID\", class_mode=\"sparse\", target_size=(224, 224), batch_size=32)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_dataframe(dataframe=df_val, directory=validation_image_directory, x_col=\"imageFile\", y_col=\"classID\", class_mode=\"sparse\", target_size=(224, 224), batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THIS ONE TAKES A WHILE TO RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2561/2561 [==============================] - 5425s 2s/step - loss: 2.1858 - accuracy: 0.1743 - val_loss: 2.0752 - val_accuracy: 0.1920\n",
      "Epoch 2/10\n",
      "2561/2561 [==============================] - 5402s 2s/step - loss: 2.0286 - accuracy: 0.1903 - val_loss: 1.9645 - val_accuracy: 0.1976\n",
      "Epoch 3/10\n",
      "2561/2561 [==============================] - 5412s 2s/step - loss: 1.9512 - accuracy: 0.2000 - val_loss: 1.9069 - val_accuracy: 0.2030\n",
      "Epoch 4/10\n",
      "2561/2561 [==============================] - 5411s 2s/step - loss: 1.9039 - accuracy: 0.2079 - val_loss: 1.8649 - val_accuracy: 0.2279\n",
      "Epoch 5/10\n",
      "2561/2561 [==============================] - 5406s 2s/step - loss: 1.8574 - accuracy: 0.2211 - val_loss: 1.8172 - val_accuracy: 0.2340\n",
      "Epoch 6/10\n",
      "2561/2561 [==============================] - 5408s 2s/step - loss: 1.8093 - accuracy: 0.2350 - val_loss: 1.7792 - val_accuracy: 0.2594\n",
      "Epoch 7/10\n",
      "2561/2561 [==============================] - 5412s 2s/step - loss: 1.7710 - accuracy: 0.2487 - val_loss: 1.7377 - val_accuracy: 0.2403\n",
      "Epoch 8/10\n",
      "2561/2561 [==============================] - 5426s 2s/step - loss: 1.7272 - accuracy: 0.2675 - val_loss: 1.7635 - val_accuracy: 0.3102\n",
      "Epoch 9/10\n",
      "2561/2561 [==============================] - 5409s 2s/step - loss: 1.6980 - accuracy: 0.2914 - val_loss: 1.6748 - val_accuracy: 0.2980\n",
      "Epoch 10/10\n",
      "2561/2561 [==============================] - 5464s 2s/step - loss: 1.6674 - accuracy: 0.3119 - val_loss: 1.7147 - val_accuracy: 0.2764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d6cf7690>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, validation_data=val_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "Found 0 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 30690 invalid image filename(s) in x_col=\"imageFile\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Asked to retrieve element 0, but the Sequence has length 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_dataframe(dataframe\u001b[38;5;241m=\u001b[39mdf_test, directory\u001b[38;5;241m=\u001b[39mtrain_image_directory, x_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimageFile\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# use the model to make predictions\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# the predictions are probabilities for each class, so take the class with the highest probability as the prediction\u001b[39;00m\n\u001b[1;32m     11\u001b[0m predicted_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/preprocessing/image.py:103\u001b[0m, in \u001b[0;36mIterator.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 103\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    104\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to retrieve element \u001b[39m\u001b[38;5;132;01m{idx}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut the Sequence \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas length \u001b[39m\u001b[38;5;132;01m{length}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx\u001b[38;5;241m=\u001b[39midx, length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m         np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_batches_seen)\n",
      "\u001b[0;31mValueError\u001b[0m: Asked to retrieve element 0, but the Sequence has length 0"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "# create a generator for the test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=df_test, directory=train_image_directory, x_col=\"imageFile\", y_col=None, class_mode=None, target_size=(224, 224), batch_size=32, shuffle=False)\n",
    "\n",
    "# use the model to make predictions\n",
    "predictions = model.predict(test_generator)\n",
    "\n",
    "# the predictions are probabilities for each class, so take the class with the highest probability as the prediction\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"[INFO] evaluating network...\")\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"test loss: {:.2f}\".format(test_loss))\n",
    "print(\"test accuracy: {:.2f}\".format(test_acc))\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(\"bttai-nybg-2024.model\", save_format=\"smallVGNNET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "N = 10\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), model.history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), model.history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), model.history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), model.history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
