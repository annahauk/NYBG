{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages for Xception Model\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_directory = \"/Users/annahauk/Desktop/NYBG/bttai-nybg-2024/BTTAIxNYBG-train/BTTAIxNYBG-train\"\n",
    "validation_image_directory = \"/Users/annahauk/Desktop/NYBG/bttai-nybg-2024/BTTAIxNYBG-validation/BTTAIxNYBG-validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train = \"/Users/annahauk/Desktop/NYBG/bttai-nybg-2024/BTTAIxNYBG-train.csv\"\n",
    "df_train = pd.read_csv(filename_train, header = 0)\n",
    "filename_test = \"/Users/annahauk/Desktop/NYBG/bttai-nybg-2024/BTTAIxNYBG-test.csv\"\n",
    "df_test = pd.read_csv(filename_test, header = 0)\n",
    "filename_val = \"/Users/annahauk/Desktop/NYBG/bttai-nybg-2024/BTTAIxNYBG-validation.csv\"\n",
    "df_val = pd.read_csv(filename_val, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>classLabel</th>\n",
       "      <th>classID</th>\n",
       "      <th>source</th>\n",
       "      <th>imageFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>occluded-specimens</td>\n",
       "      <td>8</td>\n",
       "      <td>L</td>\n",
       "      <td>a1a8b48e8cb142b3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>microscope-slides</td>\n",
       "      <td>6</td>\n",
       "      <td>L</td>\n",
       "      <td>79599db2ac9092b6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>illustrations-color</td>\n",
       "      <td>2</td>\n",
       "      <td>BHL</td>\n",
       "      <td>c449696f2f0d0d92.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>illustrations-color</td>\n",
       "      <td>2</td>\n",
       "      <td>P</td>\n",
       "      <td>80a8f4a393b4e08c.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>animal-specimens</td>\n",
       "      <td>0</td>\n",
       "      <td>AK</td>\n",
       "      <td>041a1c6e73313638.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>occluded-specimens</td>\n",
       "      <td>8</td>\n",
       "      <td>L</td>\n",
       "      <td>ccf1b1ccacb8f8b3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>live-plants</td>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>246c8e9612111a24.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>biocultural-specimens</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>b0b337313164a0f0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>microscope-slides</td>\n",
       "      <td>6</td>\n",
       "      <td>L</td>\n",
       "      <td>b3931bc4cc2b2925.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>illustrations-gray</td>\n",
       "      <td>3</td>\n",
       "      <td>BR</td>\n",
       "      <td>ebf7674e4c2c0e6e.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID             classLabel  classID source             imageFile\n",
       "0         2     occluded-specimens        8      L  a1a8b48e8cb142b3.jpg\n",
       "1         3      microscope-slides        6      L  79599db2ac9092b6.jpg\n",
       "2         4    illustrations-color        2    BHL  c449696f2f0d0d92.jpg\n",
       "3         5    illustrations-color        2      P  80a8f4a393b4e08c.jpg\n",
       "4         6       animal-specimens        0     AK  041a1c6e73313638.jpg\n",
       "5         8     occluded-specimens        8      L  ccf1b1ccacb8f8b3.jpg\n",
       "6        11            live-plants        4     US  246c8e9612111a24.jpg\n",
       "7        12  biocultural-specimens        1      C  b0b337313164a0f0.jpg\n",
       "8        13      microscope-slides        6      L  b3931bc4cc2b2925.jpg\n",
       "9        15     illustrations-gray        3     BR  ebf7674e4c2c0e6e.jpg"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['uniqueID', 'classLabel', 'classID', 'source', 'imageFile'], dtype='object')\n",
      "Index(['uniqueID', 'classLabel', 'classID', 'source', 'imageFile'], dtype='object')\n",
      "Index(['uniqueID', 'imageFile'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns)\n",
    "print(df_val.columns)\n",
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train an Xception model\n",
    "# create the base pre-trained model\n",
    "\n",
    "df_train[\"classID\"] = df_train[\"classID\"].astype(str)\n",
    "df_val[\"classID\"] = df_val[\"classID\"].astype(str)\n",
    "\n",
    "base_model = Xception(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer\n",
    "predictions = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional Xception layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 81945 validated image filenames belonging to 10 classes.\n",
      "Found 10244 validated image filenames belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"imageFile\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    df_train,\n",
    "    directory=train_image_directory,\n",
    "    x_col='imageFile',\n",
    "    y_col='classID',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    df_val,\n",
    "    directory=validation_image_directory,\n",
    "    x_col='imageFile',\n",
    "    y_col='classID',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/q6bbfq_s68l_m1x6yxgvqnt80000gn/T/ipykernel_37014/3634458605.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 175s 2s/step - loss: 0.3512 - accuracy: 0.8943 - val_loss: 0.3293 - val_accuracy: 0.9000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 171s 2s/step - loss: 0.3287 - accuracy: 0.9000 - val_loss: 0.3287 - val_accuracy: 0.9000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 173s 2s/step - loss: 0.3276 - accuracy: 0.9000 - val_loss: 0.3280 - val_accuracy: 0.9000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 174s 2s/step - loss: 0.3273 - accuracy: 0.9000 - val_loss: 0.3279 - val_accuracy: 0.9000\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 173s 2s/step - loss: 0.3271 - accuracy: 0.9000 - val_loss: 0.3272 - val_accuracy: 0.9000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 177s 2s/step - loss: 0.3269 - accuracy: 0.9000 - val_loss: 0.3271 - val_accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 181s 2s/step - loss: 0.3269 - accuracy: 0.9000 - val_loss: 0.3282 - val_accuracy: 0.9000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 175s 2s/step - loss: 0.3268 - accuracy: 0.9000 - val_loss: 0.3267 - val_accuracy: 0.9000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 177s 2s/step - loss: 0.3267 - accuracy: 0.9000 - val_loss: 0.3267 - val_accuracy: 0.9000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 183s 2s/step - loss: 0.3265 - accuracy: 0.9000 - val_loss: 0.3268 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x34f255390>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 Xception blocks, i.e. we will freeze\n",
    "# the first 115 layers and unfreeze the rest:\n",
    "for layer in model.layers[:115]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[115:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use Adam with a low learning rate\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)\n",
    "\n",
    "# save the model\n",
    "model.save('xception_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
