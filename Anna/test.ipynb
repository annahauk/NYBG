{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYBG DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train = \"/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-train.csv\"\n",
    "df_train = pd.read_csv(filename_train, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>classLabel</th>\n",
       "      <th>classID</th>\n",
       "      <th>source</th>\n",
       "      <th>imageFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>occluded-specimens</td>\n",
       "      <td>8</td>\n",
       "      <td>L</td>\n",
       "      <td>a1a8b48e8cb142b3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>microscope-slides</td>\n",
       "      <td>6</td>\n",
       "      <td>L</td>\n",
       "      <td>79599db2ac9092b6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>illustrations-color</td>\n",
       "      <td>2</td>\n",
       "      <td>BHL</td>\n",
       "      <td>c449696f2f0d0d92.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>illustrations-color</td>\n",
       "      <td>2</td>\n",
       "      <td>P</td>\n",
       "      <td>80a8f4a393b4e08c.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>animal-specimens</td>\n",
       "      <td>0</td>\n",
       "      <td>AK</td>\n",
       "      <td>041a1c6e73313638.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81941</th>\n",
       "      <td>122874</td>\n",
       "      <td>micrographs-transmission-light</td>\n",
       "      <td>5</td>\n",
       "      <td>Tw</td>\n",
       "      <td>2424355d5438181c.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81942</th>\n",
       "      <td>122875</td>\n",
       "      <td>illustrations-color</td>\n",
       "      <td>2</td>\n",
       "      <td>BHL</td>\n",
       "      <td>b28acccccecad04c.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81943</th>\n",
       "      <td>122876</td>\n",
       "      <td>microscope-slides</td>\n",
       "      <td>6</td>\n",
       "      <td>L</td>\n",
       "      <td>78f6868694a6669c.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81944</th>\n",
       "      <td>122877</td>\n",
       "      <td>live-plants</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>5c6162948949510a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81945</th>\n",
       "      <td>122879</td>\n",
       "      <td>biocultural-specimens</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>58583a38131331e8.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81946 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uniqueID                      classLabel  classID source  \\\n",
       "0             2              occluded-specimens        8      L   \n",
       "1             3               microscope-slides        6      L   \n",
       "2             4             illustrations-color        2    BHL   \n",
       "3             5             illustrations-color        2      P   \n",
       "4             6                animal-specimens        0     AK   \n",
       "...         ...                             ...      ...    ...   \n",
       "81941    122874  micrographs-transmission-light        5     Tw   \n",
       "81942    122875             illustrations-color        2    BHL   \n",
       "81943    122876               microscope-slides        6      L   \n",
       "81944    122877                     live-plants        4      E   \n",
       "81945    122879           biocultural-specimens        1      C   \n",
       "\n",
       "                  imageFile  \n",
       "0      a1a8b48e8cb142b3.jpg  \n",
       "1      79599db2ac9092b6.jpg  \n",
       "2      c449696f2f0d0d92.jpg  \n",
       "3      80a8f4a393b4e08c.jpg  \n",
       "4      041a1c6e73313638.jpg  \n",
       "...                     ...  \n",
       "81941  2424355d5438181c.jpg  \n",
       "81942  b28acccccecad04c.jpg  \n",
       "81943  78f6868694a6669c.jpg  \n",
       "81944  5c6162948949510a.jpg  \n",
       "81945  58583a38131331e8.jpg  \n",
       "\n",
       "[81946 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided Example Starting Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset & Define image directory\n",
    "df = pd.read_csv('/path/to/your/dataset.csv')  \n",
    "# NOTE: if we have seperate train dataset and validate dataset, you may want to seperately load it with pd.read_csv() \n",
    "# Please update the paths when running this code\n",
    "# train_df = pd.read_csv('/path/to/your/train_dataset.csv')\n",
    "# validate_df = pd.read_csv('/path/to/your/validate_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image_directory = '/path/to/image/directory/'  # Please update this path when running this code\n",
    "\n",
    "# Preprocessing function to load and process images\n",
    "def load_and_preprocess_image(filename, target_size=(224, 224)):\n",
    "    img_path = os.path.join(image_directory, filename)\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Model expects a batch of images\n",
    "    return img_array / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "# Apply preprocessing to all images\n",
    "df['imageData'] = df['imageFile'].apply(load_and_preprocess_image)\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "### Note: This is a common step in ML training, but in this challenge, since the validation set is provided separately, there is no need to call this function to distinguish between validation and train set.\n",
    "# train_df, validate_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data augmentation configuration for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Note: No augmentation for validation data, only rescaling\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Convert dataframe to a format suitable for the model training\n",
    "def df_to_dataset(dataframe, datagen, batch_size=32):\n",
    "    datagen.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        directory=image_directory,\n",
    "        x_col='imageFile',\n",
    "        y_col='classLabel',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'  # Change this if not a multiclass classification\n",
    "    )\n",
    "\n",
    "# Create datasets for training and validation\n",
    "train_dataset = df_to_dataset(train_df, train_datagen)\n",
    "validation_dataset = df_to_dataset(validate_df, validation_datagen)\n",
    "\n",
    "# This setup is now ready for training with model.fit using the train_dataset and validation_dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
