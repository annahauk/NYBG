{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Model for NYBG Data\n",
    "\n",
    "### Anna Hauk"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 2,
>>>>>>> bac37c4 (new)
   "metadata": {},
   "outputs": [],
   "source": [
    "# mute the Requirement already satisfied messages\n",
    "#! pip install opencv-python\n",
    "#! pip install scikit-image\n",
    "#! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": 3,
>>>>>>> bac37c4 (new)
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from skimage.io import imread\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": 4,
>>>>>>> bac37c4 (new)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>classLabel</th>\n",
       "      <th>classID</th>\n",
       "      <th>source</th>\n",
       "      <th>imageFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>occluded-specimens</td>\n",
       "      <td>8</td>\n",
       "      <td>L</td>\n",
       "      <td>a1a8b48e8cb142b3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>microscope-slides</td>\n",
       "      <td>6</td>\n",
       "      <td>L</td>\n",
       "      <td>79599db2ac9092b6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>illustrations-color</td>\n",
       "      <td>2</td>\n",
       "      <td>BHL</td>\n",
       "      <td>c449696f2f0d0d92.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>illustrations-color</td>\n",
       "      <td>2</td>\n",
       "      <td>P</td>\n",
       "      <td>80a8f4a393b4e08c.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>animal-specimens</td>\n",
       "      <td>0</td>\n",
       "      <td>AK</td>\n",
       "      <td>041a1c6e73313638.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID           classLabel  classID source             imageFile\n",
       "0         2   occluded-specimens        8      L  a1a8b48e8cb142b3.jpg\n",
       "1         3    microscope-slides        6      L  79599db2ac9092b6.jpg\n",
       "2         4  illustrations-color        2    BHL  c449696f2f0d0d92.jpg\n",
       "3         5  illustrations-color        2      P  80a8f4a393b4e08c.jpg\n",
       "4         6     animal-specimens        0     AK  041a1c6e73313638.jpg"
      ]
     },
<<<<<<< HEAD
     "execution_count": 43,
=======
     "execution_count": 4,
>>>>>>> bac37c4 (new)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_train = \"/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-train.csv\"\n",
    "df_train = pd.read_csv(filename_train, header = 0)\n",
    "filename_test = \"/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-test.csv\"\n",
    "df_test = pd.read_csv(filename_test, header = 0)\n",
    "filename_val = \"/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-validation.csv\"\n",
    "df_val = pd.read_csv(filename_val, header = 0)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
=======
   "execution_count": 20,
>>>>>>> bac37c4 (new)
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset & Define image directory\n",
    "df = pd.read_csv('/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-train.csv')  \n",
    "\n",
    "# Load test and validation datasets\n",
    "test_df = pd.read_csv('/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-test.csv')\n",
    "validate_df = pd.read_csv('/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-validation.csv')\n",
    "\n",
    "image_directory = \"/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-train/BTTAIxNYBG-train\"  # Please update this path when running this code\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 45,
=======
   "execution_count": 21,
>>>>>>> bac37c4 (new)
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to load and process images\n",
    "def load_and_preprocess_image(filename, target_size=(224, 224)):  #target size sets the image size to 224x224\n",
    "    img_path = os.path.join(image_directory, filename) # Create image path\n",
    "    img = image.load_img(img_path, target_size=target_size) # Load image and resize\n",
    "    img_array = image.img_to_array(img) # Convert image to numpy array of shape (224, 224, 3)\n",
    "    # this is done to add a dimension to the image, so that it can be passed to the model\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Model expects a batch of images\n",
    "    #expand_dims is used to add a dimension to the image, so that it can be passed to the model\n",
    "\n",
    "    return img_array / 255.0  # Normalize to [0, 1]\n",
    "    # divide by 255 because the model expects the input to be in the range [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This next cell took me 11 min to run...."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 46,
=======
   "execution_count": 7,
>>>>>>> bac37c4 (new)
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to all images\n",
    "df['imageData'] = df['imageFile'].apply(load_and_preprocess_image)\n",
    "# this will apply the function to each row of the dataframe"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_df, validate_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "### Note: This is a common step in ML training, but in this challenge, since the validation set is provided separately, there is no need to call this function to distinguish between validation and train set.\n",
    "# train_df, validate_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 65556 validated image filenames belonging to 10 classes.\n",
      "Found 16390 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Note: This is a common step in ML training, but in this challenge, since the validation set is provided separately, there is no need to call this function to distinguish between validation and train set.\n",
    "train_df, validate_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
>>>>>>> bac37c4 (new)
    "# Data augmentation configuration for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Note: No augmentation for validation data, only rescaling\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Convert dataframe to a format suitable for the model training\n",
    "def df_to_dataset(dataframe, datagen, batch_size=32):\n",
    "    datagen.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        directory=image_directory,\n",
    "        x_col='imageFile',\n",
    "        y_col='classLabel',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'  # Change this if not a multiclass classification\n",
    "    )\n",
    "\n",
    "# Create datasets for training and validation\n",
    "train_dataset = df_to_dataset(train_df, train_datagen)\n",
    "validation_dataset = df_to_dataset(validate_df, validation_datagen)\n",
    "\n",
    "# This setup is now ready for training with model.fit using the train_dataset and validation_dataset"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the KNN image classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the image data\n",
    "X_train = np.array(train_df['imageData'].tolist())\n",
    "X_test = np.array(df_test['imageData'].tolist())\n",
    "X_val = np.array(df_val['imageData'].tolist())\n",
    "\n",
    "# Load the labels\n",
    "y_train = df_train['classLabel']\n",
    "y_test = df_test['classLabel']\n",
    "y_val = df_val['classLabel']\n",
    "\n",
    "# Flatten the image data\n",
    "n_samples, nx, ny, nz = X_train.shape\n",
    "X_train = X_train.reshape((n_samples, nx * ny * nz))\n",
    "\n",
    "n_samples, nx, ny, nz = X_test.shape\n",
    "X_test = X_test.reshape((n_samples, nx * ny * nz))\n",
    "\n",
    "n_samples, nx, ny, nz = X_val.shape\n",
    "X_val = X_val.reshape((n_samples, nx * ny * nz))\n",
    "\n",
    "# Create the KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", knn.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniqueID       int64\n",
       "classLabel    object\n",
       "classID        int64\n",
       "source        object\n",
       "imageFile     object\n",
       "imageData     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[CategoricalAccuracy()])\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# The model is now ready for training\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# The model is now trained and can be used for prediction\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1105\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1102\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle input: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1107\u001b[0m             _type_name(x), _type_name(y)\n\u001b[1;32m   1108\u001b[0m         )\n\u001b[1;32m   1109\u001b[0m     )\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapter_cls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData adapters should be mutually exclusive for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandling inputs. Found multiple adapters \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[1;32m   1115\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# define the knn model for image classification\n",
    "\n",
    "# Import required packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=CategoricalCrossentropy(), metrics=[CategoricalAccuracy()])\n",
    "# The model is now ready for training\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, validation_data=validation_dataset, epochs=10)\n",
    "# The model is now trained and can be used for prediction"
   ]
  },
  {
   "cell_type": "code",
>>>>>>> bac37c4 (new)
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "train_df.head()"
=======
    "# Load the model\n",
    "model = tf.keras.models.load_model('plant_classifier.h5')\n",
    "\n",
    "# Predict on test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_dataset = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=image_directory,\n",
    "    x_col='imageFile',\n",
    "    y_col='classLabel',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n"
>>>>>>> bac37c4 (new)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = train_df['imageData']\n",
    "y = train_df['classLabel']\n",
    "\n",
    "# Flatten the images\n",
    "#X = [x.flatten() for x in X]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "# Create and train the KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train score:\", knn.score(X_train, y_train))\n",
    "#print(\"Test score:\", knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore this cause this is what I did to process the images that worked but we have a similar func above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_images_from_directory(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Add or modify if you have other image types\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = image.load_img(img_path, target_size=(224, 224)) # resize image to 224x224\n",
    "            img = image.img_to_array(img) # convert image to numpy array\n",
    "            images.append(img) # add image to the list as an array\n",
    "    return np.array(images) # convert list of arrays to a single array dimensions: (n_images, 224, 224, 3)\n",
    "\n",
    "train = load_images_from_directory(\"/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-train/BTTAIxNYBG-train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
