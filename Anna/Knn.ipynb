{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model\n",
    "### Anna Hauk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.15.0)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (10.0.1)\n"
     ]
    }
   ],
   "source": [
    "#! pip install opencv-python\n",
    "#! pip install scikit-image\n",
    "#! pip install tensorflow\n",
    "#! pip install keras\n",
    "#! pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from skimage.io import imread\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>classLabel</th>\n",
       "      <th>classID</th>\n",
       "      <th>source</th>\n",
       "      <th>imageFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>occluded-specimens</td>\n",
       "      <td>8</td>\n",
       "      <td>L</td>\n",
       "      <td>a1a8b48e8cb142b3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>microscope-slides</td>\n",
       "      <td>6</td>\n",
       "      <td>L</td>\n",
       "      <td>79599db2ac9092b6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>illustrations-color</td>\n",
       "      <td>2</td>\n",
       "      <td>BHL</td>\n",
       "      <td>c449696f2f0d0d92.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>illustrations-color</td>\n",
       "      <td>2</td>\n",
       "      <td>P</td>\n",
       "      <td>80a8f4a393b4e08c.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>animal-specimens</td>\n",
       "      <td>0</td>\n",
       "      <td>AK</td>\n",
       "      <td>041a1c6e73313638.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID           classLabel  classID source             imageFile\n",
       "0         2   occluded-specimens        8      L  a1a8b48e8cb142b3.jpg\n",
       "1         3    microscope-slides        6      L  79599db2ac9092b6.jpg\n",
       "2         4  illustrations-color        2    BHL  c449696f2f0d0d92.jpg\n",
       "3         5  illustrations-color        2      P  80a8f4a393b4e08c.jpg\n",
       "4         6     animal-specimens        0     AK  041a1c6e73313638.jpg"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_train = \"/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-train.csv\"\n",
    "df_train = pd.read_csv(filename_train, header = 0)\n",
    "\n",
    "filename_test = \"/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-test.csv\"\n",
    "df_test = pd.read_csv(filename_test, header = 0)\n",
    "\n",
    "filename_val = \"/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-validation.csv\"\n",
    "df_val = pd.read_csv(filename_val, header = 0)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset & Define image directory\n",
    "df = pd.read_csv('/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-train.csv')\n",
    "\n",
    "# Load test and validation datasets\n",
    "test_df = pd.read_csv('/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-test.csv')\n",
    "validate_df = pd.read_csv('/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-validation.csv')\n",
    "\n",
    "image_directory = \"/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-train/BTTAIxNYBG-train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to load and process images\n",
    "def load_and_preprocess_image(filename, target_size=(224, 224)):  # target size sets the image size to 224x224\n",
    "    img_path = os.path.join(image_directory, filename)  # Create image path\n",
    "    img = image.load_img(img_path, target_size=target_size)  # Load image and resize\n",
    "    img_array = image.img_to_array(img)  # Convert image to numpy array of shape (224, 224, 3)\n",
    "    # this is done to add a dimension to the image, so that it can be passed to the model\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Model expects a batch of images\n",
    "    # expand_dims is used to add a dimension to the image, so that it can be passed to the model\n",
    "\n",
    "    return img_array / 255.0  # Normalize to [0, 1]\n",
    "    # divide by 255 because the model expects the input to be in the range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to all images\n",
    "df['imageData'] = df['imageFile'].apply(load_and_preprocess_image)\n",
    "# this will apply the function to each row of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-test/BTTAIxNYBG-test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprocessing to test and validation datasets\n",
    "#test_df['imageData'] = test_df['imageFile'].apply(load_and_preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_directory = \"/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-validation/BTTAIxNYBG-validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate_df['imageData'] = validate_df['imageFile'].apply(load_and_preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and validation sets\n",
    "#train_df, validate_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "### Note: This is a common step in ML training, but in this challenge, since the validation set is provided separately, \n",
    "### there is no need to call this function to distinguish between validation and train set.\n",
    "# train_df, validate_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format validation and train datasets so the ImageData column can be passed to a Knn model\n",
    "train_images = np.vstack(train_df['imageData'].values)\n",
    "#train_images = np.vstack(train_df['imageData'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 65556 invalid image filename(s) in x_col=\"imageFile\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 16390 invalid image filename(s) in x_col=\"imageFile\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation configuration for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Note: No augmentation for validation data, only rescaling\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Convert dataframe to a format suitable for the model training\n",
    "def df_to_dataset(dataframe, datagen, batch_size=32):\n",
    "    return datagen.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        directory=image_directory,\n",
    "        x_col='imageFile',\n",
    "        y_col='classLabel',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'  # Change this if not a multiclass classification\n",
    "    )\n",
    "\n",
    "# Create datasets for training and validation\n",
    "train_dataset = df_to_dataset(train_df, train_datagen)\n",
    "validation_dataset = df_to_dataset(validate_df, validation_datagen)\n",
    "#test_dataset = df_to_dataset(test_df, validation_datagen)\n",
    "\n",
    "# This setup is now ready for training with model.fit using the train_dataset and validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: []\n",
      "labels: []\n"
     ]
    }
   ],
   "source": [
    "# Get one batch of data\n",
    "images, labels = next(train_dataset)\n",
    "\n",
    "# Print out the images and labels\n",
    "print(\"images:\", images)\n",
    "print(\"labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the image data\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimageData\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimageData\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m      7\u001b[0m X_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(df_val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimageData\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the KNN image classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the image data\n",
    "X_train = np.array(train_df['imageData'].tolist())\n",
    "X_test = np.array(df_test['imageData'].tolist())\n",
    "X_val = np.array(df_val['imageData'].tolist())\n",
    "\n",
    "# Load the labels\n",
    "y_train = df_train['classLabel']\n",
    "y_test = df_test['classLabel']\n",
    "y_val = df_val['classLabel']\n",
    "\n",
    "# Flatten the image data\n",
    "n_samples, nx, ny, nz = X_train.shape\n",
    "X_train = X_train.reshape((n_samples, nx * ny * nz))\n",
    "\n",
    "n_samples, nx, ny, nz = X_test.shape\n",
    "X_test = X_test.reshape((n_samples, nx * ny * nz))\n",
    "\n",
    "n_samples, nx, ny, nz = X_val.shape\n",
    "X_val = X_val.reshape((n_samples, nx * ny * nz))\n",
    "\n",
    "# Create the KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = train_df['imageData']\n",
    "y = train_df['classLabel']\n",
    "\n",
    "# Flatten the images\n",
    "#X = [x.flatten() for x in X]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "# Create and train the KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train score:\", knn.score(X_train, y_train))\n",
    "#print(\"Test score:\", knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore this cause this is what I did to process the images that worked but we have a similar func above\n",
    "\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_images_from_directory(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Add or modify if you have other image types\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = image.load_img(img_path, target_size=(224, 224)) # resize image to 224x224\n",
    "            img = image.img_to_array(img) # convert image to numpy array\n",
    "            images.append(img) # add image to the list as an array\n",
    "    return np.array(images) # convert list of arrays to a single array dimensions: (n_images, 224, 224, 3)\n",
    "\n",
    "train = load_images_from_directory(\"/Users/annahauk/Desktop/bttai-nybg-2024/BTTAIxNYBG-train/BTTAIxNYBG-train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
